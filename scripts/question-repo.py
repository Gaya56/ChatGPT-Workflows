import openai
import os
import time
import glob
import fnmatch
from typing import List, Dict, Any

"""
question-repo.py
----------------
An interactive script that uses GPT to provide Q&A about your repository.
It references:
- index.md (generated by create-index.py in your repo root)
- find-path.txt (from openai-find-paths.py in the OpenAI folder)

It can also scan additional code for context if desired,
and can rotate through multiple API keys if rate-limited.

Usage:
1. Place this script in your repository (e.g., scripts/question-repo.py).
2. Update 'api_keys' with your own GPT/OpenAI keys (or use secrets).
3. Run: python question-repo.py
4. Interactively ask questions about the codebase structure, lines, or architecture.
Type special commands like:
scan: path=src
search: keyword=main
to load additional code context as needed.
"""

# ------------------------------------------------------------------------------
# 1) Configure your list of API keys for potential rotation
# ------------------------------------------------------------------------------
api_keys = [
#"",
]
current_key_index = 0

# Set up the initial OpenAI environment with the first key
os.environ["OPENAI_API_KEY"] = api_keys[current_key_index]
openai.api_key = api_keys[current_key_index]

# ------------------------------------------------------------------------------
# 2) Define system prompt
# ------------------------------------------------------------------------------
system_prompt = """You are an expert code analyst and documentation processor.
Respond to queries about this repository's structure, code files, architecture,
and recommended modifications. Provide specific line numbers or file paths
where possible, referencing context from index.md, find-path.txt, or scanned code.
Always maintain a helpful, organized tone with clear bullet points and references.
"""

# ------------------------------------------------------------------------------
# 3) Utility for rotating API keys on rate limit or errors
# ------------------------------------------------------------------------------
def rotate_api_key() -> None:
    global current_key_index
    current_key_index = (current_key_index + 1) % len(api_keys)
    os.environ["OPENAI_API_KEY"] = api_keys[current_key_index]
    openai.api_key = api_keys[current_key_index]
    print(f"[INFO] Switched to API key #{current_key_index + 1}")

# ------------------------------------------------------------------------------
# 4) Send messages to GPT with basic error handling and key rotation
# ------------------------------------------------------------------------------
def send_message_to_gpt(messages: List[Dict[str, Any]]) -> str:
    global current_key_index

    for _ in range(len(api_keys)):
        try:
            completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=messages,
                max_tokens=1024, # keep tokens moderate
                temperature=0.3
            )
            if completion.choices:
                return completion.choices[0].message.content
            else:
                return "No response received."
        except Exception as e:
            error_str = str(e).lower()
            if ("rate limit" in error_str or "quota" in error_str or
                "capacity" in error_str):
                print(f"[WARN] API key #{current_key_index + 1} hit rate limit. "
                      f"Rotating to next key...")
                rotate_api_key()
                time.sleep(1)
            elif "maximum context length" in error_str:
                print("[WARN] Reached max context length, rotating key...")
                rotate_api_key()
                time.sleep(1)
            else:
                return f"Error occurred while calling OpenAI API: {str(e)}"

    return "All available API keys are rate-limited or exhausted. Please try again later."

# ------------------------------------------------------------------------------
# 5) Print GPT responses in a clearer format
# ------------------------------------------------------------------------------
def print_with_formatting(text: str):
    print("\n" + "="*80)
    print(text)
    print("="*80 + "\n")

# ------------------------------------------------------------------------------
# 6) Read the index.md and find-path.txt, but do NOT feed them fully upfront.
# Instead, store them in memory (or a short summary).
# ------------------------------------------------------------------------------
def read_repo_context(index_path="index.md", find_path_file="OpenAI/find-path.txt") -> Dict[str, str]:
    """
    Returns a dict with minimal content or short text from index.md / find-path.txt.
    We do not want to dump them all in one big chunk. The user can request details later.
    """
    context_data = {
        "index_md": "",
        "find_path_txt": ""
    }

    # index.md
    if os.path.exists(index_path):
        try:
            with open(index_path, "r", encoding="utf-8", errors="ignore") as idx:
                # Read some lines or do a short read
                text = idx.read(2000) # read at most 2000 chars to keep it small
                if len(text) == 2000:
                    text += "\n... [truncated] ..."
                context_data["index_md"] = text
        except Exception as e:
            context_data["index_md"] = f"(Couldn't read index.md: {str(e)})"
    else:
        context_data["index_md"] = "(No index.md found)"

    # find-path.txt
    if os.path.exists(find_path_file):
        try:
            with open(find_path_file, "r", encoding="utf-8", errors="ignore") as fpf:
                # Similarly keep it short
                text = fpf.read(2000)
                if len(text) == 2000:
                    text += "\n... [truncated] ..."
                context_data["find_path_txt"] = text
        except Exception as e:
            context_data["find_path_txt"] = f"(Couldn't read find-path.txt: {str(e)})"
    else:
        context_data["find_path_txt"] = "(No find-path.txt found)"

    return context_data

# ------------------------------------------------------------------------------
# 7) Functions to scan code on demand (triggered by user commands)
# ------------------------------------------------------------------------------
def scan_additional_code(base_path: str, max_files=2, max_chars=1500) -> str:
    """
    Scan up to `max_files` from the specified base_path for demonstration
    and return partial code as a snippet. We do not read all code at once.
    """
    code_extensions = ["*.js", "*.jsx", "*.ts", "*.tsx", "*.svelte", "*.py"]
    exclude_dirs = ["*node_modules*", "*.git*", "*OpenAI*", "*__pycache__*"]

    context = f"== Additional Code Snippets for path: {base_path} ==\n\n"
    collected_files = []

    # For each extension, gather up to `max_files` matching files
    for ext in code_extensions:
        pattern = os.path.join(base_path, "**", ext)
        candidates = glob.glob(pattern, recursive=True)
        filtered = []
        # Exclude unwanted directories
        for c in candidates:
            skip = any(fnmatch.fnmatch(c, ex) for ex in exclude_dirs)
            if not skip:
                filtered.append(c)
        # Take up to max_files from each extension
        chosen = filtered[:max_files]
        collected_files.extend(chosen)

    # Deduplicate, sort
    collected_files = sorted(set(collected_files))

    # Read partial content
    for file_path in collected_files:
        if os.path.exists(file_path):
            try:
                with open(file_path, "r", encoding="utf-8", errors="ignore") as cf:
                    content = cf.read(max_chars)
                    if len(content) >= max_chars:
                        content += "\n... [content truncated] ..."
                    context += f"FILE: {file_path}\n```\n{content}\n```\n\n"
            except Exception as e:
                context += f"FILE: {file_path}\n(Couldn't read: {str(e)})\n\n"

    return context

def scan_code_for_query(keyword: str, max_chars=1500) -> str:
    """
    Scan only .py files matching the user's keyword in the path,
    returning partial code content for each matching file.
    """
    context = f"== Filtered Code Snippets for keyword: '{keyword}' ==\n\n"
    matched_files = []

    for file_path in glob.glob("**/*.py", recursive=True):
        if keyword.lower() in file_path.lower():
            matched_files.append(file_path)

    for file_path in matched_files:
        try:
            with open(file_path, "r", encoding="utf-8") as cf:
                content = cf.read(max_chars)
                if len(content) >= max_chars:
                    content += "\n... [content truncated] ..."
                context += f"FILE: {file_path}\n```\n{content}\n```\n\n"
        except Exception as e:
            context += f"(Couldn't read {file_path}: {str(e)})\n\n"
    return context

# ------------------------------------------------------------------------------
# 8) Main interactive flow
# ------------------------------------------------------------------------------
def main():
    # Read minimal context for index.md and find-path.txt
    repo_info = read_repo_context(index_path="index.md", find_path_file="OpenAI/find-path.txt")

    # Just a short summary or partial text for the initial conversation
    short_context = (
        "== index.md (partial) ==\n" + repo_info["index_md"] + "\n\n"
        "== find-path.txt (partial) ==\n" + repo_info["find_path_txt"] + "\n\n"
        "You can type commands like:\n"
        " scan: path=YOUR_FOLDER\n"
        " search: keyword=SOMETHING\n"
        "to load code snippets on demand, so we don't overload the context.\n"
    )

    conversation_history = [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": (
                "Welcome to the repository Q&A!\n"
                "I have an 'index.md' and a 'find-path.txt' describing files.\n"
                "We also have code in different folders, but we'll load it on-demand.\n"
                "Please provide an overview of this codebase if possible,\n"
                "and then I'll ask follow-up questions or request code scans.\n\n"
                "---\n" + short_context
            )
        },
    ]

    print(f"[INFO] Initialized question-repo script with {len(api_keys)} API keys.")
    print("[INFO] Starting analysis. Ask follow-up questions after the initial answer.\n")

    # Get the initial GPT response
    response = send_message_to_gpt(conversation_history)
    conversation_history.append({"role": "assistant", "content": response})
    print_with_formatting(response)

    print("Type a question or command (e.g., 'scan: path=src') or 'exit' to quit.\n")

    while True:
        user_input = input("> ")
        if user_input.lower().strip() in ["exit", "quit"]:
            print("Exiting question-repo session.")
            break

        # Check if the user wants to scan code
        if user_input.lower().startswith("scan:"):
            # e.g. "scan: path=src"
            parts = user_input.split("=", 1)
            if len(parts) == 2:
                path_value = parts[1].strip()
                # Load code from that path
                snippet = scan_additional_code(path_value)
                # Summarize snippet or just directly pass it in
                # For simplicity, let's just pass it directly:
                conversation_history.append(
                    {"role": "user", "content": f"Here is code from '{path_value}':\n{snippet}"}
                )
            else:
                print("[WARN] Invalid 'scan:' command format. Use 'scan: path=XYZ'")
                continue

        elif user_input.lower().startswith("search:"):
            # e.g. "search: keyword=main"
            parts = user_input.split("=", 1)
            if len(parts) == 2:
                keyword_value = parts[1].strip()
                snippet = scan_code_for_query(keyword_value)
                conversation_history.append(
                    {"role": "user", "content": f"Search results for '{keyword_value}':\n{snippet}"}
                )
            else:
                print("[WARN] Invalid 'search:' command format. Use 'search: keyword=XYZ'")
                continue
        else:
            # Normal user question
            conversation_history.append({"role": "user", "content": user_input})

        print("[INFO] Processing your query...\n")
        response = send_message_to_gpt(conversation_history)
        conversation_history.append({"role": "assistant", "content": response})
        print_with_formatting(response)

if __name__ == "__main__":
    main()